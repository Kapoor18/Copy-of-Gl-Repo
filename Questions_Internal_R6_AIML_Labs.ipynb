{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Questions_Internal_R6_AIML_Labs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zUZjPnVXGz0Z"
      },
      "source": [
        "# The Iris Dataset\n",
        "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
        "\n",
        "The dataset contains a set of 150 records under five attributes - petal length, petal width, sepal length, sepal width and species."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZOk8Eu4_t70R"
      },
      "source": [
        "Firstly, let's select TensorFlow version 2.x in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H6RZUm0p4wYJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63b7bc4f-fab0-4163-b3c6-e83032c96ea5"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TWi96z-8SyX0",
        "colab": {}
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5-vVQBBqg7DI"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kE0EDKvQhEIe"
      },
      "source": [
        "### Import dataset\n",
        "- Import iris dataset\n",
        "- Import the dataset using sklearn library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IOOWpD26Haq3",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ta8YqInTh5v5"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HERt3drbhX0i"
      },
      "source": [
        "### Get features and label from the dataset in separate variable\n",
        "- you can get the features using .data method\n",
        "- you can get the features using .target method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0cV-_qHAHyvE",
        "colab": {}
      },
      "source": [
        "X= iris.data\n",
        "Y= iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSm-yg_FcwvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "806d13ba-e7d7-47b3-e4bb-33b28aee6e41"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VebFM0a1c7zm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "48014646-151b-4e47-803f-f4756d6aa0f5"
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qg1A2lkUjFak"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YErwYLCH0N_"
      },
      "source": [
        "### Create train and test data\n",
        "- use train_test_split to get train and test set\n",
        "- set a random_state: 1\n",
        "- test_size: 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TYKNJL85h7pQ",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y ,test_size= 0.25, random_state=1, stratify=Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g0KVP17Ozaix"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SIjqxbhWv1zv"
      },
      "source": [
        "### One-hot encode the labels\n",
        "- convert class vectors (integers) to binary class matrix\n",
        "- convert labels\n",
        "- number of classes: 3\n",
        "- we are doing this to use categorical_crossentropy as loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R9vv-_gpyLY9",
        "colab": {}
      },
      "source": [
        "\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, 3)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy0y1Hp6anTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee9fdd82-e8b5-47ea-ad9a-420b5f2c4803"
      },
      "source": [
        "Y_train"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD0Jd4tkfFiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0db4e02e-2766-4774-bc1c-720978896073"
      },
      "source": [
        "Y_train.shape ## There are 112 matrices with 3*3 dimensions"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btnHx6oYanaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6a8f5db-fa12-4a65-f1e3-e0d35435b3e6"
      },
      "source": [
        "Y_test.shape ## There are 38 matrices with 3*3 dimensions"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ovjLyYzWkO9s"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hbIFzoPNSyYo"
      },
      "source": [
        "### Initialize a sequential model\n",
        "- Define a sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4FvSbf1UjHtl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38b95fbd-971a-43e1-a138-e7892c8ac893"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "# Using Tensorflow Keras instead of the original Keras\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "#Initialize sequential model\n",
        "model= Sequential()\n",
        "\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dGMy999vlacX"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "72ibK5Jxm8iL"
      },
      "source": [
        "### Add a layer\n",
        "- Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3\n",
        "- Apply Softmax on Dense Layer outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uZKrBNSRm_o9",
        "colab": {}
      },
      "source": [
        "#Add Dense Layer  applying softmax\n",
        "\n",
        "#Add an input layer \n",
        "model.add(Dense(3, activation='softmax', input_shape=(4,)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i4uiTH8plmNX"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yJL8n8vcSyYz"
      },
      "source": [
        "### Compile the model\n",
        "- Use SGD as Optimizer\n",
        "- Use categorical_crossentropy as loss function\n",
        "- Use accuracy as metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tc_-fjIEk1ve",
        "colab": {}
      },
      "source": [
        "#Compile the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sihIGbRll_jT"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "54ZZCfNGlu0i"
      },
      "source": [
        "### Summarize the model\n",
        "- Check model layers\n",
        "- Understand number of trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "elER3F_4ln8n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6a43f59-18c7-47bf-e4d4-b3ac76522769"
      },
      "source": [
        "model.summary\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f0f3129ff60>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2PiP7j3Vmj4p"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rWdbfFCXmCHt"
      },
      "source": [
        "### Fit the model\n",
        "- Give train data as training features and labels\n",
        "- Epochs: 100\n",
        "- Give validation data as testing features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cO1c-5tjmBVZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bbb1a893-868d-4784-a140-aea2f3e0cd5e"
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 150\n",
        "\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_split=.1, verbose=True)\n",
        "loss,accuracy  = model.evaluate(X_test, Y_test, verbose=False)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 100 samples, validate on 12 samples\n",
            "Epoch 1/100\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.5554 - accuracy: 0.7800 - val_loss: 0.7007 - val_accuracy: 0.6667\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.5535 - accuracy: 0.7800 - val_loss: 0.6974 - val_accuracy: 0.6667\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 0s 114us/sample - loss: 0.5517 - accuracy: 0.7800 - val_loss: 0.6942 - val_accuracy: 0.6667\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.5499 - accuracy: 0.7800 - val_loss: 0.6910 - val_accuracy: 0.6667\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.5482 - accuracy: 0.7800 - val_loss: 0.6878 - val_accuracy: 0.6667\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.5465 - accuracy: 0.7800 - val_loss: 0.6846 - val_accuracy: 0.6667\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 0s 106us/sample - loss: 0.5448 - accuracy: 0.7900 - val_loss: 0.6814 - val_accuracy: 0.6667\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 0s 97us/sample - loss: 0.5431 - accuracy: 0.7900 - val_loss: 0.6781 - val_accuracy: 0.6667\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.5414 - accuracy: 0.7900 - val_loss: 0.6749 - val_accuracy: 0.6667\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 0s 115us/sample - loss: 0.5398 - accuracy: 0.7900 - val_loss: 0.6717 - val_accuracy: 0.6667\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 0s 98us/sample - loss: 0.5382 - accuracy: 0.7900 - val_loss: 0.6685 - val_accuracy: 0.6667\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 0s 102us/sample - loss: 0.5366 - accuracy: 0.7900 - val_loss: 0.6653 - val_accuracy: 0.6667\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.5351 - accuracy: 0.7900 - val_loss: 0.6621 - val_accuracy: 0.6667\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 0s 96us/sample - loss: 0.5335 - accuracy: 0.7900 - val_loss: 0.6590 - val_accuracy: 0.6667\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 0s 99us/sample - loss: 0.5320 - accuracy: 0.7900 - val_loss: 0.6558 - val_accuracy: 0.6667\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.5305 - accuracy: 0.7900 - val_loss: 0.6526 - val_accuracy: 0.6667\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 0s 84us/sample - loss: 0.5290 - accuracy: 0.7900 - val_loss: 0.6495 - val_accuracy: 0.6667\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 0s 119us/sample - loss: 0.5275 - accuracy: 0.7900 - val_loss: 0.6463 - val_accuracy: 0.6667\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 0s 131us/sample - loss: 0.5261 - accuracy: 0.7900 - val_loss: 0.6432 - val_accuracy: 0.6667\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.5247 - accuracy: 0.7900 - val_loss: 0.6400 - val_accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 0s 101us/sample - loss: 0.5233 - accuracy: 0.7900 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 0s 107us/sample - loss: 0.5219 - accuracy: 0.7900 - val_loss: 0.6338 - val_accuracy: 0.6667\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.5205 - accuracy: 0.7900 - val_loss: 0.6307 - val_accuracy: 0.6667\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 0s 146us/sample - loss: 0.5192 - accuracy: 0.7900 - val_loss: 0.6276 - val_accuracy: 0.6667\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 0s 141us/sample - loss: 0.5178 - accuracy: 0.7900 - val_loss: 0.6245 - val_accuracy: 0.6667\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 0s 133us/sample - loss: 0.5165 - accuracy: 0.7900 - val_loss: 0.6214 - val_accuracy: 0.6667\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 0s 112us/sample - loss: 0.5152 - accuracy: 0.7900 - val_loss: 0.6183 - val_accuracy: 0.6667\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 0s 139us/sample - loss: 0.5139 - accuracy: 0.7900 - val_loss: 0.6153 - val_accuracy: 0.6667\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 0s 125us/sample - loss: 0.5126 - accuracy: 0.7900 - val_loss: 0.6122 - val_accuracy: 0.6667\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 0s 131us/sample - loss: 0.5114 - accuracy: 0.7900 - val_loss: 0.6092 - val_accuracy: 0.6667\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 0s 175us/sample - loss: 0.5101 - accuracy: 0.7900 - val_loss: 0.6062 - val_accuracy: 0.6667\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 0s 129us/sample - loss: 0.5089 - accuracy: 0.7900 - val_loss: 0.6032 - val_accuracy: 0.6667\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 0s 161us/sample - loss: 0.5077 - accuracy: 0.7900 - val_loss: 0.6002 - val_accuracy: 0.6667\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 0s 109us/sample - loss: 0.5065 - accuracy: 0.7900 - val_loss: 0.5972 - val_accuracy: 0.6667\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 0s 147us/sample - loss: 0.5053 - accuracy: 0.8000 - val_loss: 0.5942 - val_accuracy: 0.6667\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 0s 116us/sample - loss: 0.5041 - accuracy: 0.8000 - val_loss: 0.5913 - val_accuracy: 0.6667\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.5029 - accuracy: 0.8000 - val_loss: 0.5883 - val_accuracy: 0.6667\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 0s 121us/sample - loss: 0.5018 - accuracy: 0.8000 - val_loss: 0.5854 - val_accuracy: 0.6667\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 0s 137us/sample - loss: 0.5007 - accuracy: 0.8000 - val_loss: 0.5825 - val_accuracy: 0.6667\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 0s 135us/sample - loss: 0.4995 - accuracy: 0.8000 - val_loss: 0.5796 - val_accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.4984 - accuracy: 0.8000 - val_loss: 0.5767 - val_accuracy: 0.6667\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 0s 145us/sample - loss: 0.4973 - accuracy: 0.8000 - val_loss: 0.5738 - val_accuracy: 0.6667\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 0s 125us/sample - loss: 0.4962 - accuracy: 0.8000 - val_loss: 0.5710 - val_accuracy: 0.6667\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 0s 174us/sample - loss: 0.4951 - accuracy: 0.8000 - val_loss: 0.5681 - val_accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 0s 172us/sample - loss: 0.4941 - accuracy: 0.8000 - val_loss: 0.5653 - val_accuracy: 0.6667\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 0s 132us/sample - loss: 0.4930 - accuracy: 0.8000 - val_loss: 0.5625 - val_accuracy: 0.6667\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 0s 136us/sample - loss: 0.4920 - accuracy: 0.8000 - val_loss: 0.5596 - val_accuracy: 0.6667\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 0s 134us/sample - loss: 0.4909 - accuracy: 0.8000 - val_loss: 0.5569 - val_accuracy: 0.6667\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 0s 157us/sample - loss: 0.4899 - accuracy: 0.8000 - val_loss: 0.5541 - val_accuracy: 0.6667\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 0s 143us/sample - loss: 0.4889 - accuracy: 0.8000 - val_loss: 0.5513 - val_accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 0s 143us/sample - loss: 0.4879 - accuracy: 0.8000 - val_loss: 0.5486 - val_accuracy: 0.6667\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.4869 - accuracy: 0.8000 - val_loss: 0.5458 - val_accuracy: 0.6667\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 0s 138us/sample - loss: 0.4859 - accuracy: 0.8000 - val_loss: 0.5431 - val_accuracy: 0.7500\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 0s 171us/sample - loss: 0.4849 - accuracy: 0.8000 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 0s 143us/sample - loss: 0.4840 - accuracy: 0.8000 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 0s 128us/sample - loss: 0.4830 - accuracy: 0.8000 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 0s 163us/sample - loss: 0.4820 - accuracy: 0.8000 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 0s 158us/sample - loss: 0.4811 - accuracy: 0.8000 - val_loss: 0.5298 - val_accuracy: 0.7500\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 0s 163us/sample - loss: 0.4802 - accuracy: 0.8000 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 0s 154us/sample - loss: 0.4792 - accuracy: 0.8000 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 0s 161us/sample - loss: 0.4783 - accuracy: 0.8000 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 0s 142us/sample - loss: 0.4774 - accuracy: 0.8000 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 0s 130us/sample - loss: 0.4765 - accuracy: 0.8000 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.4756 - accuracy: 0.8100 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 0s 177us/sample - loss: 0.4747 - accuracy: 0.8100 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 0s 131us/sample - loss: 0.4739 - accuracy: 0.8100 - val_loss: 0.5093 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 0s 130us/sample - loss: 0.4730 - accuracy: 0.8100 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 0s 142us/sample - loss: 0.4721 - accuracy: 0.8100 - val_loss: 0.5043 - val_accuracy: 0.7500\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 0s 148us/sample - loss: 0.4713 - accuracy: 0.8100 - val_loss: 0.5018 - val_accuracy: 0.7500\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 0s 140us/sample - loss: 0.4704 - accuracy: 0.8100 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 0s 124us/sample - loss: 0.4696 - accuracy: 0.8100 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 0s 141us/sample - loss: 0.4688 - accuracy: 0.8100 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 0s 105us/sample - loss: 0.4679 - accuracy: 0.8100 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 0s 128us/sample - loss: 0.4671 - accuracy: 0.8100 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 0s 141us/sample - loss: 0.4663 - accuracy: 0.8100 - val_loss: 0.4874 - val_accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 0s 155us/sample - loss: 0.4655 - accuracy: 0.8100 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 0s 128us/sample - loss: 0.4647 - accuracy: 0.8100 - val_loss: 0.4827 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.4639 - accuracy: 0.8100 - val_loss: 0.4803 - val_accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 0s 145us/sample - loss: 0.4631 - accuracy: 0.8100 - val_loss: 0.4780 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 0s 128us/sample - loss: 0.4623 - accuracy: 0.8100 - val_loss: 0.4758 - val_accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 0s 146us/sample - loss: 0.4616 - accuracy: 0.8100 - val_loss: 0.4735 - val_accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 0s 139us/sample - loss: 0.4608 - accuracy: 0.8100 - val_loss: 0.4712 - val_accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 0s 128us/sample - loss: 0.4600 - accuracy: 0.8100 - val_loss: 0.4690 - val_accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 0s 145us/sample - loss: 0.4593 - accuracy: 0.8100 - val_loss: 0.4668 - val_accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 0s 130us/sample - loss: 0.4585 - accuracy: 0.8100 - val_loss: 0.4645 - val_accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 0s 176us/sample - loss: 0.4578 - accuracy: 0.8100 - val_loss: 0.4624 - val_accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 0s 147us/sample - loss: 0.4570 - accuracy: 0.8100 - val_loss: 0.4602 - val_accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 0s 103us/sample - loss: 0.4563 - accuracy: 0.8100 - val_loss: 0.4580 - val_accuracy: 0.8333\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 0s 133us/sample - loss: 0.4556 - accuracy: 0.8100 - val_loss: 0.4559 - val_accuracy: 0.8333\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 0s 139us/sample - loss: 0.4548 - accuracy: 0.8100 - val_loss: 0.4537 - val_accuracy: 0.8333\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 0s 175us/sample - loss: 0.4541 - accuracy: 0.8100 - val_loss: 0.4516 - val_accuracy: 0.8333\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 0s 111us/sample - loss: 0.4534 - accuracy: 0.8100 - val_loss: 0.4495 - val_accuracy: 0.8333\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 0s 140us/sample - loss: 0.4527 - accuracy: 0.8100 - val_loss: 0.4474 - val_accuracy: 0.8333\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 0s 119us/sample - loss: 0.4520 - accuracy: 0.8100 - val_loss: 0.4454 - val_accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 0s 154us/sample - loss: 0.4513 - accuracy: 0.8100 - val_loss: 0.4433 - val_accuracy: 0.8333\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 0s 137us/sample - loss: 0.4506 - accuracy: 0.8100 - val_loss: 0.4413 - val_accuracy: 0.8333\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 0s 131us/sample - loss: 0.4499 - accuracy: 0.8100 - val_loss: 0.4392 - val_accuracy: 0.8333\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 0s 152us/sample - loss: 0.4492 - accuracy: 0.8100 - val_loss: 0.4372 - val_accuracy: 0.8333\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 0s 120us/sample - loss: 0.4485 - accuracy: 0.8100 - val_loss: 0.4352 - val_accuracy: 0.8333\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 0s 146us/sample - loss: 0.4479 - accuracy: 0.8100 - val_loss: 0.4333 - val_accuracy: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVbbez9ataxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1e1f55dd-8669-4178-f7ec-e50d94c0bb92"
      },
      "source": [
        "loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Accuracy: %.3f'  % acc)\n",
        "print('Loss: %.3f' % loss)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.737\n",
            "Loss: 0.606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "re9ItAR3yS3J"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "liw0IFf9yVqH"
      },
      "source": [
        "### Make predictions\n",
        "- Predict labels on one row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfz82dsnskp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "107efadd-7bee-4da5-b31b-5c2e71748668"
      },
      "source": [
        "model.predict(X_test[0:1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04243349, 0.2592638 , 0.69830275]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H5sBybi6mlLl",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hSUgMq3m0bG7"
      },
      "source": [
        "### Compare the prediction with actual label\n",
        "- Print the same row as done in the previous step but of actual labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K5WbwVPyz-qQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c8fc129-84ea-45b9-c0cd-b03c7b8620c0"
      },
      "source": [
        "Y_test[0:1]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FrTKwbgE7NFT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YeoiMbH7djEv"
      },
      "source": [
        "# Stock prices dataset\n",
        "The data is of tock exchange's stock listings for each trading day of 2010 to 2016.\n",
        "\n",
        "## Description\n",
        "A brief description of columns.\n",
        "- open: The opening market price of the equity symbol on the date\n",
        "- high: The highest market price of the equity symbol on the date\n",
        "- low: The lowest recorded market price of the equity symbol on the date\n",
        "- close: The closing recorded price of the equity symbol on the date\n",
        "- symbol: Symbol of the listed company\n",
        "- volume: Total traded volume of the equity symbol on the date\n",
        "- date: Date of record"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RSoYY2nII_UW"
      },
      "source": [
        "In this assignment, we will work on the stock prices dataset named \"prices.csv\". Task is to create a Neural Network to classify closing price for a stock based on some parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v9Ws2l6jdLa_"
      },
      "source": [
        "Firstly, let's select TensorFlow version 2.x in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "407SiobOdLbL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a272327e-adc3-41a1-81f4-43b88b7c1bed"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PGqq9f8VdLba",
        "colab": {}
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_88voqAH-O6J"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dRHCeJqP-evf"
      },
      "source": [
        "### Load the data\n",
        "- load the csv file and read it using pandas\n",
        "- file name is prices.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cKVH5v7r-RmC",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "outputId": "8f0c817e-0c39-4333-ecee-28f72e783f67"
      },
      "source": [
        "# run this cell to upload file using GUI if you are using google colab\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0cd4af48-94c5-414e-8ab5-4179ac9a2a35\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0cd4af48-94c5-414e-8ab5-4179ac9a2a35\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gr4YcffYd1FQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "2b17caf0-3d08-4f16-dd94-cbc52e8c8ae1"
      },
      "source": [
        "# run this cell to to mount the google drive if you are using google colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df= pd.read_csv('/content/prices.csv')\n",
        "df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  date symbol        open  ...         low        high     volume\n",
              "0  2016-01-05 00:00:00   WLTW  123.430000  ...  122.309998  126.250000  2163600.0\n",
              "1  2016-01-06 00:00:00   WLTW  125.239998  ...  119.940002  125.540001  2386400.0\n",
              "2  2016-01-07 00:00:00   WLTW  116.379997  ...  114.930000  119.739998  2489500.0\n",
              "3  2016-01-08 00:00:00   WLTW  115.480003  ...  113.500000  117.440002  2006300.0\n",
              "4  2016-01-11 00:00:00   WLTW  117.010002  ...  114.089996  117.330002  1408600.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gDC6cSW_FSK",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwYOotHD1z9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HlLKVPVH_BCT"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZxoGynuBeO4t"
      },
      "source": [
        "### Drop null\n",
        "- Drop null values if any"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_yuwJJIeeUaD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5c60b72c-6350-4bd4-d468-2568fca8e2b9"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "date      0\n",
              "symbol    1\n",
              "open      1\n",
              "close     1\n",
              "low       1\n",
              "high      1\n",
              "volume    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKvy8zLT36GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(axis=0,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9J4BlzVA_gZd"
      },
      "source": [
        "### Drop columnns\n",
        "- Now, we don't need \"date\", \"volume\" and \"symbol\" column\n",
        "- drop \"date\", \"volume\" and \"symbol\" column from the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IKEK8aEE_Csx",
        "colab": {}
      },
      "source": [
        "df_modi = df.drop(['date','volume','symbol'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cTPhO6v-AiZt"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SsZXmF3NAkna"
      },
      "source": [
        "### Print the dataframe\n",
        "- print the modified dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aKs04iIHAjxN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b7e304d0-c685-4545-d507-b300585f684c"
      },
      "source": [
        "df_modi"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88884</th>\n",
              "      <td>78.019997</td>\n",
              "      <td>77.269997</td>\n",
              "      <td>76.510002</td>\n",
              "      <td>78.260002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88885</th>\n",
              "      <td>58.080002</td>\n",
              "      <td>58.099998</td>\n",
              "      <td>57.750000</td>\n",
              "      <td>58.470001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88886</th>\n",
              "      <td>18.139999</td>\n",
              "      <td>17.690001</td>\n",
              "      <td>17.650000</td>\n",
              "      <td>18.200001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88887</th>\n",
              "      <td>16.320000</td>\n",
              "      <td>16.389999</td>\n",
              "      <td>15.970000</td>\n",
              "      <td>16.389999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88888</th>\n",
              "      <td>44.110001</td>\n",
              "      <td>43.610001</td>\n",
              "      <td>43.529999</td>\n",
              "      <td>44.340000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88889 rows  4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             open       close         low        high\n",
              "0      123.430000  125.839996  122.309998  126.250000\n",
              "1      125.239998  119.980003  119.940002  125.540001\n",
              "2      116.379997  114.949997  114.930000  119.739998\n",
              "3      115.480003  116.620003  113.500000  117.440002\n",
              "4      117.010002  114.970001  114.089996  117.330002\n",
              "...           ...         ...         ...         ...\n",
              "88884   78.019997   77.269997   76.510002   78.260002\n",
              "88885   58.080002   58.099998   57.750000   58.470001\n",
              "88886   18.139999   17.690001   17.650000   18.200001\n",
              "88887   16.320000   16.389999   15.970000   16.389999\n",
              "88888   44.110001   43.610001   43.529999   44.340000\n",
              "\n",
              "[88889 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C8u_jlbABTip"
      },
      "source": [
        "### Get features and label from the dataset in separate variable\n",
        "- Let's separate labels and features now. We are going to predict the value for \"close\" column so that will be our label. Our features will be \"open\", \"low\", \"high\"\n",
        "- Take \"open\" \"low\", \"high\" columns as features\n",
        "- Take \"close\" column as label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xQjCMzUXBJbg",
        "colab": {}
      },
      "source": [
        "X= df_mod.drop(['close'],axis=1)\n",
        "y = df_mod['close']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6vGtnapgBIJm"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8pZAKdJ5gcrm"
      },
      "source": [
        "### Create train and test sets\n",
        "- Split the data into training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KalRqA6Rgqsn",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1,test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aTAKzlxZBz0z"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O7BU2qxEg0Ki"
      },
      "source": [
        "### Scaling\n",
        "- Scale the data (features only)\n",
        "- Use StandarScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AcO8SlhPhBkR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "76b6ee46-249d-4c79-d06d-990d683428a9"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train =sc.fit_transform(X_train)\n",
        "X_test =sc.fit_transform(X_test)\n",
        "X_train"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.13105339, -0.1356901 , -0.13434787],\n",
              "       [ 0.24158521,  0.25423878,  0.23913162],\n",
              "       [-0.48277869, -0.48177067, -0.48859961],\n",
              "       ...,\n",
              "       [-0.70838982, -0.71641249, -0.70971955],\n",
              "       [-0.30659919, -0.30038856, -0.30447229],\n",
              "       [-0.38877402, -0.38894064, -0.39434148]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3TWpN0nVTpUx"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_sj0LYNkhR-L"
      },
      "source": [
        "### Convert data to NumPy array\n",
        "- Convert features and labels to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X6mIfuTxhbTT",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WbESkpe7hiVk"
      },
      "source": [
        "### Reshape features\n",
        "- Reshape the features to make it suitable for input in the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv0pPC7K46TY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "979c3580-c3c8-4aa4-eab9-49dcac3105f3"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62222, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K_ZG_CWthpTP",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
        "X_test= X_test.reshape(X_test.shape[0],X_test.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wmXUGc2oTspa"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cl2M9whFh6mh"
      },
      "source": [
        "### Define Model\n",
        "- Initialize a Sequential model\n",
        "- Add a Flatten layer\n",
        "- Add a Dense layer with one neuron as output\n",
        "  - add 'linear' as activation function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TkiBpORmiegL",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense , Flatten\n",
        "from keras.layers.advanced_activations import ReLU\n",
        "\n",
        "# define the model architecture\n",
        "\n",
        "# Initialize the constructor\n",
        "model_1 = Sequential()\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(1,activation = 'linear'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8a0wr94aTyjg"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BNZPb5lKioX0"
      },
      "source": [
        "### Compile the model\n",
        "- Compile the model\n",
        "- Use \"sgd\" optimizer\n",
        "- for calculating loss, use mean squared error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZEQUP3VaiuT2",
        "colab": {}
      },
      "source": [
        "model_1.compile(loss='mean_squared_error',\n",
        "              optimizer='sgd',)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZbBpnOtfT0wd"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n9o45OHdjDhA"
      },
      "source": [
        "### Fit the model\n",
        "- epochs: 50\n",
        "- batch size: 128\n",
        "- specify validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Y6tA30XjOH2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fce8212c-c27b-4056-8712-b27d626b157a"
      },
      "source": [
        "epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "epochs = 50\n",
        "batchsize = 128\n",
        "validation = (X_test,y_test)\n",
        "history = model_1.fit(X_train, y_train, epochs=epochs,batch_size = batchsize,validation_data=validation, verbose=True)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 62222 samples, validate on 26667 samples\n",
            "Epoch 1/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4879 - val_loss: 6.1583\n",
            "Epoch 2/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4874 - val_loss: 6.2630\n",
            "Epoch 3/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4846 - val_loss: 6.6236\n",
            "Epoch 4/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4857 - val_loss: 6.1931\n",
            "Epoch 5/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4853 - val_loss: 6.8851\n",
            "Epoch 6/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4855 - val_loss: 6.2072\n",
            "Epoch 7/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4827 - val_loss: 6.5185\n",
            "Epoch 8/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4823 - val_loss: 6.5750\n",
            "Epoch 9/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4816 - val_loss: 6.5236\n",
            "Epoch 10/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4819 - val_loss: 6.2688\n",
            "Epoch 11/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4799 - val_loss: 6.7568\n",
            "Epoch 12/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4810 - val_loss: 5.9530\n",
            "Epoch 13/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4813 - val_loss: 6.7281\n",
            "Epoch 14/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4803 - val_loss: 6.3186\n",
            "Epoch 15/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4791 - val_loss: 7.0562\n",
            "Epoch 16/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4795 - val_loss: 6.4445\n",
            "Epoch 17/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4790 - val_loss: 6.1738\n",
            "Epoch 18/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4774 - val_loss: 6.8132\n",
            "Epoch 19/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4789 - val_loss: 6.5222\n",
            "Epoch 20/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4765 - val_loss: 7.1711\n",
            "Epoch 21/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4767 - val_loss: 5.8921\n",
            "Epoch 22/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4758 - val_loss: 6.4763\n",
            "Epoch 23/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4751 - val_loss: 6.6292\n",
            "Epoch 24/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4751 - val_loss: 6.2337\n",
            "Epoch 25/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4742 - val_loss: 6.4211\n",
            "Epoch 26/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4742 - val_loss: 6.3542\n",
            "Epoch 27/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4740 - val_loss: 6.1678\n",
            "Epoch 28/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4737 - val_loss: 6.4220\n",
            "Epoch 29/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4722 - val_loss: 6.1214\n",
            "Epoch 30/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4727 - val_loss: 6.7808\n",
            "Epoch 31/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4720 - val_loss: 6.3114\n",
            "Epoch 32/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4720 - val_loss: 6.3863\n",
            "Epoch 33/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4710 - val_loss: 6.7107\n",
            "Epoch 34/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4704 - val_loss: 6.3581\n",
            "Epoch 35/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4686 - val_loss: 6.0137\n",
            "Epoch 36/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4692 - val_loss: 5.2407\n",
            "Epoch 37/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4709 - val_loss: 6.7551\n",
            "Epoch 38/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4682 - val_loss: 7.6077\n",
            "Epoch 39/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4675 - val_loss: 7.0592\n",
            "Epoch 40/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4674 - val_loss: 6.4870\n",
            "Epoch 41/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4669 - val_loss: 6.2258\n",
            "Epoch 42/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4667 - val_loss: 6.5728\n",
            "Epoch 43/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4644 - val_loss: 6.1997\n",
            "Epoch 44/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4663 - val_loss: 6.1838\n",
            "Epoch 45/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4649 - val_loss: 6.0708\n",
            "Epoch 46/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4652 - val_loss: 6.1139\n",
            "Epoch 47/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4631 - val_loss: 5.7110\n",
            "Epoch 48/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4643 - val_loss: 6.5165\n",
            "Epoch 49/50\n",
            "62222/62222 [==============================] - 1s 14us/sample - loss: 0.4622 - val_loss: 6.2404\n",
            "Epoch 50/50\n",
            "62222/62222 [==============================] - 1s 13us/sample - loss: 0.4631 - val_loss: 6.3745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AW4SEP8kT2ls"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EJDoix_7JU61"
      },
      "source": [
        "### Evaluate the model\n",
        "- Evaluate the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HdH8pYBIjHGL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "230528ae-5917-4cb1-9c01-5e425d7b7a7e"
      },
      "source": [
        "loss= model_1.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Loss: %.3f' %loss)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 6.374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hUpDD74Xjh01"
      },
      "source": [
        "### Manual predictions\n",
        "- Test the predictions on manual inputs\n",
        "- We have scaled out training data, so we need to transform our custom inputs using the object of the scaler\n",
        "- Example of manual input: [123.430000,\t122.30999, 116.250000]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fvuH-c31lLiJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ae5f4db-a858-4393-bbb4-65a5da97c7d7"
      },
      "source": [
        "sample1 = [123.430000, 122.30999, 116.250000]\n",
        "sample1 = sc.transform([sample1])\n",
        "sample1"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.70344445, 1.71268669, 1.51382269]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WSiMhJPpk3GO",
        "colab": {}
      },
      "source": [
        "manual_predict=model_1.predict([sample1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJMZJ88I8Lqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "264e6021-f51c-43b8-c0d8-e311e457297a"
      },
      "source": [
        "manual_predict"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[124.585556]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q_G1EdQ8Pp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}