{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_ExternalLab_AIML-1_Ashita.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYk8NG3yOIT9",
        "colab_type": "text"
      },
      "source": [
        "### A MNIST-like fashion product database\n",
        "\n",
        "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFO6PuxzOIT_",
        "colab_type": "text"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICvkaJnbpH5W",
        "colab_type": "code",
        "outputId": "0dd82d46-2fad-495f-e0ec-c171892f5e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==2.0        ## For changing the version of the tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/08/1ff15637a03b1565dd6cb0916b3ca6873db3a1fc69be0ed851be936e5633/tensorflow-2.0.0-cp27-cp27mu-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (1.16.4)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/3d/993131c622ae34f9401a81526853f2310a4834bd042420a7982fb5bc5fd0/tensorboard-2.0.2-py2-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 57.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (2.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (1.0.post1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (1.0.8)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (0.34.2)\n",
            "Requirement already satisfied: functools32>=3.2.3 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (3.2.3.post2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (0.7.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (2.3.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (0.1.7)\n",
            "Requirement already satisfied: enum34>=1.1.6; python_version < \"3.4\" in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (1.1.6)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0) (0.8.0)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow==2.0) (3.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (44.0.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.15.5)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==2.0) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==2.0) (5.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.5)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /usr/local/lib/python2.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.5)\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth-oauthlib, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: google-auth-oauthlib 0.4.0\n",
            "    Uninstalling google-auth-oauthlib-0.4.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-0.4.0\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.0\n",
            "    Uninstalling tensorflow-estimator-1.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-oauthlib-0.4.1 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jiznqdjzzYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import All necesssary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from keras import optimizers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Using Tensorflow Keras instead of the original Keras\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9C4aAIGOIUH",
        "colab_type": "code",
        "outputId": "5c4cbecf-eece-44f1-8e1e-698cb0cc0c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcoZBStrOIUQ",
        "colab_type": "text"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA1WsFSeOIUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnbx7TyQOIUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbiHj5YPOIUc",
        "colab_type": "code",
        "outputId": "f41e709b-4b37-4451-9820-c4c453953c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(testY[0:5])"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04eVbQxruIxu",
        "colab_type": "code",
        "outputId": "523d8457-719c-46c1-f8f0-a6340ed7e88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"Train X shape is\",trainX.shape)\n",
        "print(\"Train Y shape is \", trainY.shape)\n",
        "print(\"Test X shape is \", testX.shape)\n",
        "print(\"Test Y shape is \", testY.shape)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Train X shape is', (60000, 28, 28))\n",
            "('Train Y shape is ', (60000,))\n",
            "('Test X shape is ', (10000, 28, 28))\n",
            "('Test Y shape is ', (10000,))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDAYzkwyOIUj",
        "colab_type": "text"
      },
      "source": [
        "### Convert both training and testing labels into one-hot vectors.\n",
        "\n",
        "**Hint:** check **tf.keras.utils.to_categorical()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBlfYlANOIUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY= tf.keras.utils.to_categorical(trainY, num_classes= 10)\n",
        "testY= tf.keras.utils.to_categorical(testY, num_classes= 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RHV3b9mzOIUq",
        "colab_type": "code",
        "outputId": "11aa5826-e59c-4b73-a99e-9f767320f885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(trainY.shape)\n",
        "print('First 5 examples now are: ', trainY[0:5])"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "('First 5 examples now are: ', array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwhQ8e7VOIUw",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the data\n",
        "\n",
        "Plot first 10 images in the triaining set and their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvDML2OoOIUx",
        "colab_type": "code",
        "outputId": "6e2f588f-e001-4508-aa67-d3b472205399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(trainX[i], cmap='Greys')\n",
        "\n",
        " "
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAADjCAYAAABtjatfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4TbJGeSOIU4",
        "colab_type": "text"
      },
      "source": [
        "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNCtWaSfHxdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshape data from 2D to 1D :- 28*28 = 784\n",
        "trainX=trainX.reshape(trainX.shape[0],784).astype('float32')\n",
        "testX=testX.reshape(testX.shape[0],784).astype('float32')\n",
        "\n",
        "## Convert it in the range of 0-1 so that relu an work on it\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0                         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4S_oSoDINto5",
        "colab": {}
      },
      "source": [
        "# Initialize the constructor\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Define model architecture\n",
        "\n",
        "model.add(tf.keras.layers.Dense(784,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(784,activation='sigmoid'))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(10, activation ='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5F9pqoldNtE5",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFnNI5j6G_pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 60\n",
        "batch_size = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQpLv3aOIU_",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model using model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O59C_-IgOIVB",
        "colab_type": "code",
        "outputId": "d2c6f7f9-f48f-4031-ba36-d5eaa8bf4742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history= model.fit(trainX, trainY, batch_size=batch_size, epochs=epochs,  validation_split=.1, verbose=True)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/60\n",
            "54000/54000 [==============================] - 7s 135us/sample - loss: 2.3762 - accuracy: 0.1045 - val_loss: 2.2920 - val_accuracy: 0.1658\n",
            "Epoch 2/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 2.2830 - accuracy: 0.1915 - val_loss: 2.2635 - val_accuracy: 0.2343\n",
            "Epoch 3/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 2.2575 - accuracy: 0.2594 - val_loss: 2.2435 - val_accuracy: 0.3048\n",
            "Epoch 4/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 2.2372 - accuracy: 0.3321 - val_loss: 2.2236 - val_accuracy: 0.3775\n",
            "Epoch 5/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 2.2175 - accuracy: 0.4017 - val_loss: 2.2043 - val_accuracy: 0.4438\n",
            "Epoch 6/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 2.1979 - accuracy: 0.4631 - val_loss: 2.1847 - val_accuracy: 0.4822\n",
            "Epoch 7/60\n",
            "54000/54000 [==============================] - 7s 127us/sample - loss: 2.1787 - accuracy: 0.4950 - val_loss: 2.1653 - val_accuracy: 0.5157\n",
            "Epoch 8/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 2.1596 - accuracy: 0.5264 - val_loss: 2.1466 - val_accuracy: 0.5458\n",
            "Epoch 9/60\n",
            "54000/54000 [==============================] - 7s 127us/sample - loss: 2.1406 - accuracy: 0.5482 - val_loss: 2.1275 - val_accuracy: 0.5678\n",
            "Epoch 10/60\n",
            "54000/54000 [==============================] - 7s 127us/sample - loss: 2.1217 - accuracy: 0.5687 - val_loss: 2.1089 - val_accuracy: 0.5733\n",
            "Epoch 11/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 2.1030 - accuracy: 0.5723 - val_loss: 2.0900 - val_accuracy: 0.6015\n",
            "Epoch 12/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 2.0843 - accuracy: 0.5955 - val_loss: 2.0712 - val_accuracy: 0.6043\n",
            "Epoch 13/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 2.0657 - accuracy: 0.6025 - val_loss: 2.0529 - val_accuracy: 0.6113\n",
            "Epoch 14/60\n",
            "54000/54000 [==============================] - 7s 126us/sample - loss: 2.0471 - accuracy: 0.6045 - val_loss: 2.0342 - val_accuracy: 0.6208\n",
            "Epoch 15/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 2.0286 - accuracy: 0.6099 - val_loss: 2.0156 - val_accuracy: 0.6267\n",
            "Epoch 16/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 2.0101 - accuracy: 0.6196 - val_loss: 1.9974 - val_accuracy: 0.6330\n",
            "Epoch 17/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.9917 - accuracy: 0.6258 - val_loss: 1.9787 - val_accuracy: 0.6292\n",
            "Epoch 18/60\n",
            "54000/54000 [==============================] - 7s 127us/sample - loss: 1.9732 - accuracy: 0.6248 - val_loss: 1.9603 - val_accuracy: 0.6382\n",
            "Epoch 19/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.9548 - accuracy: 0.6329 - val_loss: 1.9421 - val_accuracy: 0.6367\n",
            "Epoch 20/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.9365 - accuracy: 0.6322 - val_loss: 1.9237 - val_accuracy: 0.6447\n",
            "Epoch 21/60\n",
            "54000/54000 [==============================] - 7s 130us/sample - loss: 1.9182 - accuracy: 0.6377 - val_loss: 1.9054 - val_accuracy: 0.6443\n",
            "Epoch 22/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.9000 - accuracy: 0.6389 - val_loss: 1.8872 - val_accuracy: 0.6453\n",
            "Epoch 23/60\n",
            "54000/54000 [==============================] - 7s 127us/sample - loss: 1.8818 - accuracy: 0.6421 - val_loss: 1.8691 - val_accuracy: 0.6393\n",
            "Epoch 24/60\n",
            "54000/54000 [==============================] - 7s 132us/sample - loss: 1.8637 - accuracy: 0.6374 - val_loss: 1.8509 - val_accuracy: 0.6500\n",
            "Epoch 25/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.8457 - accuracy: 0.6429 - val_loss: 1.8328 - val_accuracy: 0.6560\n",
            "Epoch 26/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.8277 - accuracy: 0.6466 - val_loss: 1.8149 - val_accuracy: 0.6587\n",
            "Epoch 27/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.8099 - accuracy: 0.6492 - val_loss: 1.7972 - val_accuracy: 0.6590\n",
            "Epoch 28/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.7922 - accuracy: 0.6495 - val_loss: 1.7796 - val_accuracy: 0.6568\n",
            "Epoch 29/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.7745 - accuracy: 0.6495 - val_loss: 1.7620 - val_accuracy: 0.6572\n",
            "Epoch 30/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.7571 - accuracy: 0.6494 - val_loss: 1.7445 - val_accuracy: 0.6590\n",
            "Epoch 31/60\n",
            "54000/54000 [==============================] - 7s 127us/sample - loss: 1.7398 - accuracy: 0.6519 - val_loss: 1.7272 - val_accuracy: 0.6600\n",
            "Epoch 32/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.7226 - accuracy: 0.6528 - val_loss: 1.7101 - val_accuracy: 0.6600\n",
            "Epoch 33/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.7057 - accuracy: 0.6505 - val_loss: 1.6931 - val_accuracy: 0.6648\n",
            "Epoch 34/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.6889 - accuracy: 0.6570 - val_loss: 1.6763 - val_accuracy: 0.6680\n",
            "Epoch 35/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.6723 - accuracy: 0.6573 - val_loss: 1.6601 - val_accuracy: 0.6600\n",
            "Epoch 36/60\n",
            "54000/54000 [==============================] - 7s 131us/sample - loss: 1.6559 - accuracy: 0.6569 - val_loss: 1.6434 - val_accuracy: 0.6685\n",
            "Epoch 37/60\n",
            "54000/54000 [==============================] - 7s 130us/sample - loss: 1.6397 - accuracy: 0.6593 - val_loss: 1.6273 - val_accuracy: 0.6677\n",
            "Epoch 38/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.6238 - accuracy: 0.6571 - val_loss: 1.6113 - val_accuracy: 0.6682\n",
            "Epoch 39/60\n",
            "54000/54000 [==============================] - 7s 130us/sample - loss: 1.6080 - accuracy: 0.6596 - val_loss: 1.5956 - val_accuracy: 0.6670\n",
            "Epoch 40/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.5925 - accuracy: 0.6625 - val_loss: 1.5804 - val_accuracy: 0.6618\n",
            "Epoch 41/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.5772 - accuracy: 0.6600 - val_loss: 1.5650 - val_accuracy: 0.6617\n",
            "Epoch 42/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.5621 - accuracy: 0.6598 - val_loss: 1.5501 - val_accuracy: 0.6657\n",
            "Epoch 43/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.5473 - accuracy: 0.6625 - val_loss: 1.5352 - val_accuracy: 0.6710\n",
            "Epoch 44/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.5328 - accuracy: 0.6629 - val_loss: 1.5206 - val_accuracy: 0.6792\n",
            "Epoch 45/60\n",
            "54000/54000 [==============================] - 7s 133us/sample - loss: 1.5185 - accuracy: 0.6693 - val_loss: 1.5065 - val_accuracy: 0.6750\n",
            "Epoch 46/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.5044 - accuracy: 0.6654 - val_loss: 1.4924 - val_accuracy: 0.6818\n",
            "Epoch 47/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.4906 - accuracy: 0.6716 - val_loss: 1.4786 - val_accuracy: 0.6807\n",
            "Epoch 48/60\n",
            "54000/54000 [==============================] - 7s 127us/sample - loss: 1.4771 - accuracy: 0.6725 - val_loss: 1.4653 - val_accuracy: 0.6808\n",
            "Epoch 49/60\n",
            "54000/54000 [==============================] - 7s 127us/sample - loss: 1.4638 - accuracy: 0.6711 - val_loss: 1.4519 - val_accuracy: 0.6817\n",
            "Epoch 50/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.4508 - accuracy: 0.6723 - val_loss: 1.4391 - val_accuracy: 0.6842\n",
            "Epoch 51/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.4380 - accuracy: 0.6728 - val_loss: 1.4262 - val_accuracy: 0.6868\n",
            "Epoch 52/60\n",
            "54000/54000 [==============================] - 7s 127us/sample - loss: 1.4255 - accuracy: 0.6748 - val_loss: 1.4138 - val_accuracy: 0.6867\n",
            "Epoch 53/60\n",
            "54000/54000 [==============================] - 7s 127us/sample - loss: 1.4132 - accuracy: 0.6769 - val_loss: 1.4015 - val_accuracy: 0.6857\n",
            "Epoch 54/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.4012 - accuracy: 0.6751 - val_loss: 1.3895 - val_accuracy: 0.6887\n",
            "Epoch 55/60\n",
            "54000/54000 [==============================] - 7s 127us/sample - loss: 1.3894 - accuracy: 0.6784 - val_loss: 1.3778 - val_accuracy: 0.6877\n",
            "Epoch 56/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.3778 - accuracy: 0.6778 - val_loss: 1.3662 - val_accuracy: 0.6905\n",
            "Epoch 57/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.3665 - accuracy: 0.6806 - val_loss: 1.3549 - val_accuracy: 0.6898\n",
            "Epoch 58/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.3555 - accuracy: 0.6808 - val_loss: 1.3438 - val_accuracy: 0.6892\n",
            "Epoch 59/60\n",
            "54000/54000 [==============================] - 7s 128us/sample - loss: 1.3446 - accuracy: 0.6839 - val_loss: 1.3329 - val_accuracy: 0.6920\n",
            "Epoch 60/60\n",
            "54000/54000 [==============================] - 7s 129us/sample - loss: 1.3339 - accuracy: 0.6843 - val_loss: 1.3225 - val_accuracy: 0.6902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgcKuljRDHvU",
        "colab_type": "code",
        "outputId": "a41f8f14-57df-486b-acf9-246fa8d7dca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(history.history['val_accuracy'])\n",
        "\n",
        "print(history.history['accuracy'])\n",
        "\n",
        "ta = pd.DataFrame(history.history['accuracy'])\n",
        "va = pd.DataFrame(history.history['val_accuracy'])\n",
        "\n",
        "tva = pd.concat([ta,va] , axis=1)\n",
        "\n",
        "tva.boxplot()"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.16583334, 0.23433334, 0.30483332, 0.3775, 0.44383332, 0.48216668, 0.51566666, 0.54583335, 0.5678333, 0.5733333, 0.6015, 0.60433334, 0.6113333, 0.62083334, 0.62666667, 0.633, 0.62916666, 0.63816667, 0.63666666, 0.6446667, 0.64433336, 0.64533335, 0.6393333, 0.65, 0.656, 0.6586667, 0.659, 0.65683335, 0.65716666, 0.659, 0.66, 0.66, 0.6648333, 0.668, 0.66, 0.6685, 0.6676667, 0.66816664, 0.667, 0.66183335, 0.6616667, 0.66566664, 0.671, 0.6791667, 0.675, 0.6818333, 0.6806667, 0.68083334, 0.6816667, 0.68416667, 0.6868333, 0.68666667, 0.6856667, 0.68866664, 0.68766665, 0.6905, 0.68983334, 0.68916667, 0.692, 0.69016665]\n",
            "[0.1045, 0.19148149, 0.25944445, 0.33207408, 0.40168518, 0.4630926, 0.49496296, 0.52635187, 0.54818517, 0.5687407, 0.57225925, 0.5955, 0.6024815, 0.604537, 0.60994446, 0.61955553, 0.62575924, 0.62483335, 0.6328704, 0.63218516, 0.63766664, 0.63887036, 0.64207405, 0.6374074, 0.6428518, 0.64655554, 0.6492037, 0.6494815, 0.6495, 0.6494074, 0.65185183, 0.65283334, 0.65051854, 0.657, 0.65727776, 0.6568889, 0.6592963, 0.6571481, 0.65959257, 0.66246295, 0.6600185, 0.6597593, 0.6625185, 0.6629259, 0.6693148, 0.6654074, 0.6715556, 0.672537, 0.67105556, 0.67233336, 0.6728333, 0.6748148, 0.67687035, 0.6750926, 0.6783519, 0.67777777, 0.6806296, 0.68083334, 0.6838704, 0.6842778]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f934d30c4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyHCXpAoy3CWpggx3Saqg/wfTNUjtCzTOUQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lZEAUxx1fZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b55dcb22-fe42-4b72-ddc4-bc6beb062a9d"
      },
      "source": [
        "loss, acc = model.evaluate(testX,testY, verbose=2)\n",
        "print('Accuracy: %.3f'  % acc)\n",
        "print('Loss: %.3f' % loss)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/1 - 1s - loss: 1.3172 - accuracy: 0.6814\n",
            "Accuracy: 0.681\n",
            "Loss: 1.331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdzDtGwDOIVF",
        "colab_type": "text"
      },
      "source": [
        "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kndfpdidOIVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the constructor again\n",
        "\n",
        "model1 = tf.keras.models.Sequential()\n",
        "\n",
        "## Adding batch normalizer to the above code\n",
        "\n",
        "model1.add(tf.keras.layers.Dense(784,activation='relu'))\n",
        "model1.add(tf.keras.layers.Dense(784,activation='sigmoid'))\n",
        "model1.add(tf.keras.layers.BatchNormalization())\n",
        "model1.add(tf.keras.layers.Dense(10, activation ='softmax'))\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
        "\n",
        "eopchs=60\n",
        "batch_size=10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwk3T5LJOIVN",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNLR8tcBOIVP",
        "colab_type": "code",
        "outputId": "080ab3ad-ac9d-4267-8fa0-10896a567d95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history= model1.fit(trainX, trainY, batch_size=batch_size, epochs=epochs,  validation_split=.1, verbose=True)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/60\n",
            "54000/54000 [==============================] - 8s 153us/sample - loss: 1.6813 - accuracy: 0.4293 - val_loss: 2.2826 - val_accuracy: 0.1978\n",
            "Epoch 2/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.9722 - accuracy: 0.6745 - val_loss: 2.2316 - val_accuracy: 0.1980\n",
            "Epoch 3/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.8331 - accuracy: 0.7180 - val_loss: 2.1967 - val_accuracy: 0.1978\n",
            "Epoch 4/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.7610 - accuracy: 0.7422 - val_loss: 2.1658 - val_accuracy: 0.1977\n",
            "Epoch 5/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.7143 - accuracy: 0.7573 - val_loss: 2.1383 - val_accuracy: 0.1977\n",
            "Epoch 6/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.6806 - accuracy: 0.7685 - val_loss: 2.1106 - val_accuracy: 0.1987\n",
            "Epoch 7/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.6547 - accuracy: 0.7774 - val_loss: 2.0875 - val_accuracy: 0.2000\n",
            "Epoch 8/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.6340 - accuracy: 0.7849 - val_loss: 2.0639 - val_accuracy: 0.2032\n",
            "Epoch 9/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.6170 - accuracy: 0.7912 - val_loss: 2.0419 - val_accuracy: 0.2093\n",
            "Epoch 10/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.6024 - accuracy: 0.7952 - val_loss: 2.0184 - val_accuracy: 0.2255\n",
            "Epoch 11/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.5902 - accuracy: 0.7998 - val_loss: 1.9974 - val_accuracy: 0.2488\n",
            "Epoch 12/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.5794 - accuracy: 0.8026 - val_loss: 1.9768 - val_accuracy: 0.2750\n",
            "Epoch 13/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.5696 - accuracy: 0.8066 - val_loss: 1.9552 - val_accuracy: 0.3002\n",
            "Epoch 14/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.5613 - accuracy: 0.8090 - val_loss: 1.9345 - val_accuracy: 0.3327\n",
            "Epoch 15/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.5535 - accuracy: 0.8112 - val_loss: 1.9135 - val_accuracy: 0.3627\n",
            "Epoch 16/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.5468 - accuracy: 0.8139 - val_loss: 1.8930 - val_accuracy: 0.3880\n",
            "Epoch 17/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.5405 - accuracy: 0.8156 - val_loss: 1.8715 - val_accuracy: 0.4190\n",
            "Epoch 18/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.5345 - accuracy: 0.8174 - val_loss: 1.8515 - val_accuracy: 0.4472\n",
            "Epoch 19/60\n",
            "54000/54000 [==============================] - 8s 139us/sample - loss: 0.5291 - accuracy: 0.8192 - val_loss: 1.8310 - val_accuracy: 0.4747\n",
            "Epoch 20/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.5242 - accuracy: 0.8206 - val_loss: 1.8098 - val_accuracy: 0.5187\n",
            "Epoch 21/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.5194 - accuracy: 0.8229 - val_loss: 1.7896 - val_accuracy: 0.5360\n",
            "Epoch 22/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.5152 - accuracy: 0.8242 - val_loss: 1.7678 - val_accuracy: 0.5635\n",
            "Epoch 23/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.5110 - accuracy: 0.8254 - val_loss: 1.7471 - val_accuracy: 0.5968\n",
            "Epoch 24/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.5072 - accuracy: 0.8270 - val_loss: 1.7258 - val_accuracy: 0.6185\n",
            "Epoch 25/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.5034 - accuracy: 0.8287 - val_loss: 1.7044 - val_accuracy: 0.6415\n",
            "Epoch 26/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.5001 - accuracy: 0.8299 - val_loss: 1.6829 - val_accuracy: 0.6677\n",
            "Epoch 27/60\n",
            "54000/54000 [==============================] - 8s 139us/sample - loss: 0.4969 - accuracy: 0.8305 - val_loss: 1.6616 - val_accuracy: 0.6763\n",
            "Epoch 28/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.4938 - accuracy: 0.8323 - val_loss: 1.6394 - val_accuracy: 0.6938\n",
            "Epoch 29/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.4909 - accuracy: 0.8324 - val_loss: 1.6174 - val_accuracy: 0.7130\n",
            "Epoch 30/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.4880 - accuracy: 0.8340 - val_loss: 1.5949 - val_accuracy: 0.7217\n",
            "Epoch 31/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.4853 - accuracy: 0.8347 - val_loss: 1.5722 - val_accuracy: 0.7308\n",
            "Epoch 32/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.4828 - accuracy: 0.8357 - val_loss: 1.5493 - val_accuracy: 0.7463\n",
            "Epoch 33/60\n",
            "54000/54000 [==============================] - 8s 143us/sample - loss: 0.4803 - accuracy: 0.8366 - val_loss: 1.5272 - val_accuracy: 0.7557\n",
            "Epoch 34/60\n",
            "54000/54000 [==============================] - 8s 143us/sample - loss: 0.4779 - accuracy: 0.8374 - val_loss: 1.5035 - val_accuracy: 0.7587\n",
            "Epoch 35/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.4756 - accuracy: 0.8383 - val_loss: 1.4800 - val_accuracy: 0.7662\n",
            "Epoch 36/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.4735 - accuracy: 0.8388 - val_loss: 1.4564 - val_accuracy: 0.7735\n",
            "Epoch 37/60\n",
            "54000/54000 [==============================] - 8s 139us/sample - loss: 0.4714 - accuracy: 0.8398 - val_loss: 1.4325 - val_accuracy: 0.7818\n",
            "Epoch 38/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.4692 - accuracy: 0.8402 - val_loss: 1.4095 - val_accuracy: 0.7838\n",
            "Epoch 39/60\n",
            "54000/54000 [==============================] - 8s 139us/sample - loss: 0.4672 - accuracy: 0.8407 - val_loss: 1.3854 - val_accuracy: 0.7910\n",
            "Epoch 40/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.4655 - accuracy: 0.8416 - val_loss: 1.3616 - val_accuracy: 0.7945\n",
            "Epoch 41/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.4635 - accuracy: 0.8423 - val_loss: 1.3376 - val_accuracy: 0.8013\n",
            "Epoch 42/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.4618 - accuracy: 0.8428 - val_loss: 1.3131 - val_accuracy: 0.8037\n",
            "Epoch 43/60\n",
            "54000/54000 [==============================] - 7s 139us/sample - loss: 0.4600 - accuracy: 0.8433 - val_loss: 1.2888 - val_accuracy: 0.8073\n",
            "Epoch 44/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.4584 - accuracy: 0.8435 - val_loss: 1.2649 - val_accuracy: 0.8113\n",
            "Epoch 45/60\n",
            "54000/54000 [==============================] - 8s 139us/sample - loss: 0.4566 - accuracy: 0.8441 - val_loss: 1.2409 - val_accuracy: 0.8150\n",
            "Epoch 46/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.4550 - accuracy: 0.8446 - val_loss: 1.2167 - val_accuracy: 0.8157\n",
            "Epoch 47/60\n",
            "54000/54000 [==============================] - 8s 139us/sample - loss: 0.4535 - accuracy: 0.8449 - val_loss: 1.1932 - val_accuracy: 0.8172\n",
            "Epoch 48/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.4519 - accuracy: 0.8459 - val_loss: 1.1691 - val_accuracy: 0.8223\n",
            "Epoch 49/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.4507 - accuracy: 0.8461 - val_loss: 1.1452 - val_accuracy: 0.8240\n",
            "Epoch 50/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.4491 - accuracy: 0.8469 - val_loss: 1.1208 - val_accuracy: 0.8255\n",
            "Epoch 51/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.4477 - accuracy: 0.8473 - val_loss: 1.0976 - val_accuracy: 0.8272\n",
            "Epoch 52/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.4463 - accuracy: 0.8480 - val_loss: 1.0739 - val_accuracy: 0.8295\n",
            "Epoch 53/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.4448 - accuracy: 0.8488 - val_loss: 1.0514 - val_accuracy: 0.8303\n",
            "Epoch 54/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.4435 - accuracy: 0.8487 - val_loss: 1.0280 - val_accuracy: 0.8320\n",
            "Epoch 55/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.4421 - accuracy: 0.8497 - val_loss: 1.0055 - val_accuracy: 0.8328\n",
            "Epoch 56/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.4409 - accuracy: 0.8499 - val_loss: 0.9833 - val_accuracy: 0.8340\n",
            "Epoch 57/60\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.4399 - accuracy: 0.8501 - val_loss: 0.9622 - val_accuracy: 0.8352\n",
            "Epoch 58/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.4386 - accuracy: 0.8507 - val_loss: 0.9402 - val_accuracy: 0.8372\n",
            "Epoch 59/60\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.4373 - accuracy: 0.8509 - val_loss: 0.9193 - val_accuracy: 0.8398\n",
            "Epoch 60/60\n",
            "54000/54000 [==============================] - 8s 141us/sample - loss: 0.4363 - accuracy: 0.8514 - val_loss: 0.8982 - val_accuracy: 0.8390\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoSdGYV_xwbL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9f577b77-79a1-4444-8221-6fa8651b4b59"
      },
      "source": [
        "loss, accuracy = model1.evaluate(testX,testY, verbose=2)\n",
        "print('Accuracy: %.3f'  % accuracy)\n",
        "print('Loss: %.3f' % loss)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/1 - 2s - loss: 0.8319 - accuracy: 0.8328\n",
            "Accuracy: 0.833\n",
            "Loss: 0.910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py-KwkmjOIVU",
        "colab_type": "text"
      },
      "source": [
        "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLXUE9jWOIVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the constructor again\n",
        "model2 = tf.keras.models.Sequential()\n",
        "\n",
        "#First layer \n",
        "model2.add(tf.keras.layers.Dense(784,activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(784,activation='sigmoid'))\n",
        "\n",
        "#Normalize the data\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#output layer \n",
        "model2.add(tf.keras.layers.Dense(10, activation ='softmax'))\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.001)\n",
        "model2.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
        "\n",
        "epochs=60\n",
        "batch_size=10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJUqA5T4OIVc",
        "colab_type": "code",
        "outputId": "7faa31e4-763f-4e64-d946-455c36eb5dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history= model2.fit(trainX, trainY, batch_size=batch_size, epochs=epochs,  validation_split=.1, verbose=True)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/60\n",
            "54000/54000 [==============================] - 4s 79us/sample - loss: 2.0068 - accuracy: 0.3486 - val_loss: 1.9469 - val_accuracy: 0.3675\n",
            "Epoch 2/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 1.0574 - accuracy: 0.6586 - val_loss: 1.8185 - val_accuracy: 0.4730\n",
            "Epoch 3/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.8936 - accuracy: 0.7068 - val_loss: 1.7380 - val_accuracy: 0.5313\n",
            "Epoch 4/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.8111 - accuracy: 0.7314 - val_loss: 1.6756 - val_accuracy: 0.5697\n",
            "Epoch 5/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.7572 - accuracy: 0.7482 - val_loss: 1.6201 - val_accuracy: 0.6063\n",
            "Epoch 6/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.7180 - accuracy: 0.7607 - val_loss: 1.5734 - val_accuracy: 0.6303\n",
            "Epoch 7/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.6877 - accuracy: 0.7699 - val_loss: 1.5296 - val_accuracy: 0.6545\n",
            "Epoch 8/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.6631 - accuracy: 0.7779 - val_loss: 1.4898 - val_accuracy: 0.6697\n",
            "Epoch 9/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.6427 - accuracy: 0.7838 - val_loss: 1.4504 - val_accuracy: 0.6910\n",
            "Epoch 10/60\n",
            "54000/54000 [==============================] - 4s 70us/sample - loss: 0.6254 - accuracy: 0.7889 - val_loss: 1.4135 - val_accuracy: 0.7063\n",
            "Epoch 11/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.6099 - accuracy: 0.7941 - val_loss: 1.3781 - val_accuracy: 0.7193\n",
            "Epoch 12/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.5967 - accuracy: 0.7981 - val_loss: 1.3449 - val_accuracy: 0.7272\n",
            "Epoch 13/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.5850 - accuracy: 0.8022 - val_loss: 1.3117 - val_accuracy: 0.7408\n",
            "Epoch 14/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.5746 - accuracy: 0.8055 - val_loss: 1.2804 - val_accuracy: 0.7495\n",
            "Epoch 15/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.5653 - accuracy: 0.8083 - val_loss: 1.2504 - val_accuracy: 0.7553\n",
            "Epoch 16/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.5567 - accuracy: 0.8115 - val_loss: 1.2204 - val_accuracy: 0.7613\n",
            "Epoch 17/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.5490 - accuracy: 0.8141 - val_loss: 1.1913 - val_accuracy: 0.7677\n",
            "Epoch 18/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.5418 - accuracy: 0.8165 - val_loss: 1.1634 - val_accuracy: 0.7737\n",
            "Epoch 19/60\n",
            "54000/54000 [==============================] - 4s 70us/sample - loss: 0.5353 - accuracy: 0.8193 - val_loss: 1.1367 - val_accuracy: 0.7773\n",
            "Epoch 20/60\n",
            "54000/54000 [==============================] - 4s 70us/sample - loss: 0.5293 - accuracy: 0.8207 - val_loss: 1.1096 - val_accuracy: 0.7843\n",
            "Epoch 21/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.5235 - accuracy: 0.8229 - val_loss: 1.0825 - val_accuracy: 0.7875\n",
            "Epoch 22/60\n",
            "54000/54000 [==============================] - 4s 70us/sample - loss: 0.5183 - accuracy: 0.8249 - val_loss: 1.0571 - val_accuracy: 0.7913\n",
            "Epoch 23/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.5134 - accuracy: 0.8264 - val_loss: 1.0333 - val_accuracy: 0.7938\n",
            "Epoch 24/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.5086 - accuracy: 0.8275 - val_loss: 1.0085 - val_accuracy: 0.7962\n",
            "Epoch 25/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.5042 - accuracy: 0.8292 - val_loss: 0.9851 - val_accuracy: 0.7975\n",
            "Epoch 26/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.5001 - accuracy: 0.8300 - val_loss: 0.9615 - val_accuracy: 0.8013\n",
            "Epoch 27/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4961 - accuracy: 0.8320 - val_loss: 0.9396 - val_accuracy: 0.8038\n",
            "Epoch 28/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4924 - accuracy: 0.8331 - val_loss: 0.9187 - val_accuracy: 0.8055\n",
            "Epoch 29/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4888 - accuracy: 0.8345 - val_loss: 0.8975 - val_accuracy: 0.8068\n",
            "Epoch 30/60\n",
            "54000/54000 [==============================] - 4s 70us/sample - loss: 0.4853 - accuracy: 0.8360 - val_loss: 0.8778 - val_accuracy: 0.8102\n",
            "Epoch 31/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4820 - accuracy: 0.8366 - val_loss: 0.8584 - val_accuracy: 0.8113\n",
            "Epoch 32/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4789 - accuracy: 0.8375 - val_loss: 0.8391 - val_accuracy: 0.8150\n",
            "Epoch 33/60\n",
            "54000/54000 [==============================] - 4s 67us/sample - loss: 0.4760 - accuracy: 0.8386 - val_loss: 0.8211 - val_accuracy: 0.8160\n",
            "Epoch 34/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4730 - accuracy: 0.8395 - val_loss: 0.8037 - val_accuracy: 0.8163\n",
            "Epoch 35/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4703 - accuracy: 0.8408 - val_loss: 0.7860 - val_accuracy: 0.8163\n",
            "Epoch 36/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4676 - accuracy: 0.8410 - val_loss: 0.7696 - val_accuracy: 0.8178\n",
            "Epoch 37/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4651 - accuracy: 0.8423 - val_loss: 0.7536 - val_accuracy: 0.8207\n",
            "Epoch 38/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4625 - accuracy: 0.8430 - val_loss: 0.7388 - val_accuracy: 0.8212\n",
            "Epoch 39/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4602 - accuracy: 0.8440 - val_loss: 0.7234 - val_accuracy: 0.8230\n",
            "Epoch 40/60\n",
            "54000/54000 [==============================] - 4s 72us/sample - loss: 0.4578 - accuracy: 0.8448 - val_loss: 0.7094 - val_accuracy: 0.8228\n",
            "Epoch 41/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4557 - accuracy: 0.8452 - val_loss: 0.6959 - val_accuracy: 0.8253\n",
            "Epoch 42/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4534 - accuracy: 0.8459 - val_loss: 0.6825 - val_accuracy: 0.8255\n",
            "Epoch 43/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4513 - accuracy: 0.8469 - val_loss: 0.6701 - val_accuracy: 0.8260\n",
            "Epoch 44/60\n",
            "54000/54000 [==============================] - 4s 67us/sample - loss: 0.4492 - accuracy: 0.8477 - val_loss: 0.6585 - val_accuracy: 0.8265\n",
            "Epoch 45/60\n",
            "54000/54000 [==============================] - 4s 67us/sample - loss: 0.4473 - accuracy: 0.8477 - val_loss: 0.6465 - val_accuracy: 0.8282\n",
            "Epoch 46/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4455 - accuracy: 0.8488 - val_loss: 0.6353 - val_accuracy: 0.8278\n",
            "Epoch 47/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4434 - accuracy: 0.8491 - val_loss: 0.6247 - val_accuracy: 0.8293\n",
            "Epoch 48/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4417 - accuracy: 0.8498 - val_loss: 0.6146 - val_accuracy: 0.8287\n",
            "Epoch 49/60\n",
            "54000/54000 [==============================] - 4s 67us/sample - loss: 0.4399 - accuracy: 0.8501 - val_loss: 0.6045 - val_accuracy: 0.8313\n",
            "Epoch 50/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4381 - accuracy: 0.8508 - val_loss: 0.5950 - val_accuracy: 0.8320\n",
            "Epoch 51/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4366 - accuracy: 0.8511 - val_loss: 0.5861 - val_accuracy: 0.8333\n",
            "Epoch 52/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4347 - accuracy: 0.8519 - val_loss: 0.5779 - val_accuracy: 0.8347\n",
            "Epoch 53/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4331 - accuracy: 0.8521 - val_loss: 0.5694 - val_accuracy: 0.8347\n",
            "Epoch 54/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4314 - accuracy: 0.8528 - val_loss: 0.5615 - val_accuracy: 0.8368\n",
            "Epoch 55/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4300 - accuracy: 0.8531 - val_loss: 0.5540 - val_accuracy: 0.8372\n",
            "Epoch 56/60\n",
            "54000/54000 [==============================] - 4s 67us/sample - loss: 0.4283 - accuracy: 0.8536 - val_loss: 0.5466 - val_accuracy: 0.8377\n",
            "Epoch 57/60\n",
            "54000/54000 [==============================] - 4s 67us/sample - loss: 0.4267 - accuracy: 0.8544 - val_loss: 0.5394 - val_accuracy: 0.8392\n",
            "Epoch 58/60\n",
            "54000/54000 [==============================] - 4s 68us/sample - loss: 0.4253 - accuracy: 0.8550 - val_loss: 0.5333 - val_accuracy: 0.8375\n",
            "Epoch 59/60\n",
            "54000/54000 [==============================] - 4s 69us/sample - loss: 0.4240 - accuracy: 0.8551 - val_loss: 0.5272 - val_accuracy: 0.8395\n",
            "Epoch 60/60\n",
            "54000/54000 [==============================] - 4s 67us/sample - loss: 0.4225 - accuracy: 0.8558 - val_loss: 0.5208 - val_accuracy: 0.8407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIRvvJZmxFLo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "844c8478-c86a-4b04-acf7-bb956bf54c72"
      },
      "source": [
        "print(history.history['val_accuracy'])\n",
        "\n",
        "print(history.history['accuracy'])\n",
        "\n",
        "ta = pd.DataFrame(history.history['accuracy'])\n",
        "va = pd.DataFrame(history.history['val_accuracy'])\n",
        "\n",
        "tva = pd.concat([ta,va] , axis=1)\n",
        "\n",
        "tva.boxplot()"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3675, 0.473, 0.5313333, 0.5696667, 0.6063333, 0.6303333, 0.6545, 0.66966665, 0.691, 0.70633334, 0.71933335, 0.72716665, 0.74083334, 0.7495, 0.7553333, 0.76133335, 0.76766664, 0.7736667, 0.7773333, 0.78433335, 0.7875, 0.7913333, 0.7938333, 0.79616666, 0.7975, 0.8013333, 0.8038333, 0.8055, 0.8068333, 0.81016666, 0.81133336, 0.815, 0.816, 0.81633335, 0.81633335, 0.8178333, 0.8206667, 0.8211667, 0.823, 0.82283336, 0.82533336, 0.8255, 0.826, 0.8265, 0.82816666, 0.82783335, 0.8293333, 0.8286667, 0.83133334, 0.832, 0.8333333, 0.83466667, 0.83466667, 0.83683336, 0.83716667, 0.8376667, 0.83916664, 0.8375, 0.8395, 0.84066665]\n",
            "[0.34855556, 0.6585926, 0.7068148, 0.7314444, 0.7481667, 0.7607037, 0.76985186, 0.77787036, 0.7838333, 0.78892595, 0.79411113, 0.7981296, 0.80222225, 0.80546296, 0.80833334, 0.8115185, 0.8140741, 0.81651855, 0.8192593, 0.8206667, 0.82294446, 0.8248519, 0.82640743, 0.8275, 0.8292222, 0.8300185, 0.8319815, 0.83305556, 0.83446294, 0.836, 0.8365741, 0.83753705, 0.8386296, 0.83951855, 0.8408333, 0.841, 0.8422963, 0.84301853, 0.844, 0.8447963, 0.8452037, 0.8459259, 0.8468518, 0.84768516, 0.84772223, 0.84875923, 0.84914815, 0.8497963, 0.8501296, 0.8507778, 0.8510741, 0.8518519, 0.8521482, 0.85275924, 0.8530741, 0.85355556, 0.85437036, 0.855, 0.85507405, 0.85575926]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f934d21ffd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngQx3SSqQ4S5JBfp/MOZiTQKmkWAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twt9VuN8Ze-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e66631d9-2efe-4991-a593-980206fd3d1b"
      },
      "source": [
        "loss1, acc1 = model2.evaluate(testX,testY, verbose=2)\n",
        "print('Accuracy: %.3f'  % acc1)\n",
        "print('Loss: %.3f' % loss1)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/1 - 1s - loss: 0.4649 - accuracy: 0.8257\n",
            "Accuracy: 0.826\n",
            "Loss: 0.551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CSqKvpOIVk",
        "colab_type": "text"
      },
      "source": [
        "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGAad54JOIVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the constructor again\n",
        "model3 = tf.keras.models.Sequential()\n",
        "\n",
        "#First layer \n",
        "model3.add(tf.keras.layers.Dense(100,activation='sigmoid'))\n",
        "\n",
        "#Second Dense layer \n",
        "model3.add(tf.keras.layers.Dense(100,activation='sigmoid'))\n",
        "\n",
        "#Normalize the data\n",
        "model3.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#output layer -Third layer\n",
        "model3.add(tf.keras.layers.Dense(10, activation ='softmax'))\n",
        "\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.03)\n",
        "model3.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
        "\n",
        "batch_size=10000\n",
        "epochs=60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfFGmbZLOIV5",
        "colab_type": "text"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIkbMEN5OIV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0750a9d8-9460-4011-da43-509ce016886e"
      },
      "source": [
        "history= model3.fit(trainX, trainY, batch_size=batch_size, epochs=epochs,  validation_split=.1, verbose=True)\n",
        "loss,accuracy  = model3.evaluate(testX, testY, verbose=False)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/60\n",
            "54000/54000 [==============================] - 1s 26us/sample - loss: 2.1877 - accuracy: 0.1931 - val_loss: 2.6648 - val_accuracy: 0.0942\n",
            "Epoch 2/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 1.7313 - accuracy: 0.4254 - val_loss: 2.6215 - val_accuracy: 0.0942\n",
            "Epoch 3/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 1.4821 - accuracy: 0.5188 - val_loss: 2.5850 - val_accuracy: 0.0942\n",
            "Epoch 4/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 1.3307 - accuracy: 0.5670 - val_loss: 2.5527 - val_accuracy: 0.0942\n",
            "Epoch 5/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 1.2296 - accuracy: 0.5994 - val_loss: 2.5232 - val_accuracy: 0.0942\n",
            "Epoch 6/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 1.1569 - accuracy: 0.6240 - val_loss: 2.4959 - val_accuracy: 0.0942\n",
            "Epoch 7/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 1.1013 - accuracy: 0.6419 - val_loss: 2.4702 - val_accuracy: 0.0942\n",
            "Epoch 8/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 1.0567 - accuracy: 0.6553 - val_loss: 2.4459 - val_accuracy: 0.0942\n",
            "Epoch 9/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 1.0199 - accuracy: 0.6660 - val_loss: 2.4227 - val_accuracy: 0.0942\n",
            "Epoch 10/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.9886 - accuracy: 0.6762 - val_loss: 2.4002 - val_accuracy: 0.0942\n",
            "Epoch 11/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.9620 - accuracy: 0.6839 - val_loss: 2.3787 - val_accuracy: 0.0942\n",
            "Epoch 12/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.9383 - accuracy: 0.6908 - val_loss: 2.3579 - val_accuracy: 0.0942\n",
            "Epoch 13/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.9175 - accuracy: 0.6971 - val_loss: 2.3376 - val_accuracy: 0.0942\n",
            "Epoch 14/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.8990 - accuracy: 0.7033 - val_loss: 2.3177 - val_accuracy: 0.0942\n",
            "Epoch 15/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.8823 - accuracy: 0.7089 - val_loss: 2.2983 - val_accuracy: 0.0942\n",
            "Epoch 16/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.8669 - accuracy: 0.7129 - val_loss: 2.2795 - val_accuracy: 0.0942\n",
            "Epoch 17/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.8528 - accuracy: 0.7179 - val_loss: 2.2608 - val_accuracy: 0.0955\n",
            "Epoch 18/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.8401 - accuracy: 0.7216 - val_loss: 2.2425 - val_accuracy: 0.1068\n",
            "Epoch 19/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.8282 - accuracy: 0.7251 - val_loss: 2.2245 - val_accuracy: 0.1270\n",
            "Epoch 20/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.8172 - accuracy: 0.7288 - val_loss: 2.2066 - val_accuracy: 0.1462\n",
            "Epoch 21/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.8068 - accuracy: 0.7324 - val_loss: 2.1888 - val_accuracy: 0.1607\n",
            "Epoch 22/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.7974 - accuracy: 0.7351 - val_loss: 2.1712 - val_accuracy: 0.1722\n",
            "Epoch 23/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.7883 - accuracy: 0.7384 - val_loss: 2.1538 - val_accuracy: 0.1797\n",
            "Epoch 24/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.7798 - accuracy: 0.7413 - val_loss: 2.1364 - val_accuracy: 0.1872\n",
            "Epoch 25/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.7719 - accuracy: 0.7428 - val_loss: 2.1192 - val_accuracy: 0.1983\n",
            "Epoch 26/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.7644 - accuracy: 0.7454 - val_loss: 2.1019 - val_accuracy: 0.2145\n",
            "Epoch 27/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.7570 - accuracy: 0.7479 - val_loss: 2.0847 - val_accuracy: 0.2325\n",
            "Epoch 28/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.7503 - accuracy: 0.7497 - val_loss: 2.0674 - val_accuracy: 0.2505\n",
            "Epoch 29/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.7439 - accuracy: 0.7519 - val_loss: 2.0499 - val_accuracy: 0.2715\n",
            "Epoch 30/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.7377 - accuracy: 0.7536 - val_loss: 2.0324 - val_accuracy: 0.2973\n",
            "Epoch 31/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.7320 - accuracy: 0.7552 - val_loss: 2.0150 - val_accuracy: 0.3253\n",
            "Epoch 32/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.7261 - accuracy: 0.7572 - val_loss: 1.9974 - val_accuracy: 0.3547\n",
            "Epoch 33/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.7208 - accuracy: 0.7591 - val_loss: 1.9796 - val_accuracy: 0.3827\n",
            "Epoch 34/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.7157 - accuracy: 0.7606 - val_loss: 1.9617 - val_accuracy: 0.4110\n",
            "Epoch 35/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.7108 - accuracy: 0.7624 - val_loss: 1.9438 - val_accuracy: 0.4333\n",
            "Epoch 36/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.7060 - accuracy: 0.7636 - val_loss: 1.9255 - val_accuracy: 0.4537\n",
            "Epoch 37/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.7014 - accuracy: 0.7650 - val_loss: 1.9072 - val_accuracy: 0.4728\n",
            "Epoch 38/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6970 - accuracy: 0.7662 - val_loss: 1.8886 - val_accuracy: 0.4917\n",
            "Epoch 39/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6928 - accuracy: 0.7674 - val_loss: 1.8697 - val_accuracy: 0.5075\n",
            "Epoch 40/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6888 - accuracy: 0.7686 - val_loss: 1.8506 - val_accuracy: 0.5227\n",
            "Epoch 41/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6847 - accuracy: 0.7696 - val_loss: 1.8313 - val_accuracy: 0.5363\n",
            "Epoch 42/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6809 - accuracy: 0.7706 - val_loss: 1.8119 - val_accuracy: 0.5497\n",
            "Epoch 43/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.6773 - accuracy: 0.7717 - val_loss: 1.7923 - val_accuracy: 0.5607\n",
            "Epoch 44/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6737 - accuracy: 0.7728 - val_loss: 1.7724 - val_accuracy: 0.5715\n",
            "Epoch 45/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6702 - accuracy: 0.7737 - val_loss: 1.7522 - val_accuracy: 0.5790\n",
            "Epoch 46/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.6669 - accuracy: 0.7750 - val_loss: 1.7317 - val_accuracy: 0.5888\n",
            "Epoch 47/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6636 - accuracy: 0.7757 - val_loss: 1.7109 - val_accuracy: 0.5992\n",
            "Epoch 48/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6605 - accuracy: 0.7769 - val_loss: 1.6900 - val_accuracy: 0.6062\n",
            "Epoch 49/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6574 - accuracy: 0.7779 - val_loss: 1.6687 - val_accuracy: 0.6153\n",
            "Epoch 50/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6544 - accuracy: 0.7785 - val_loss: 1.6472 - val_accuracy: 0.6223\n",
            "Epoch 51/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6516 - accuracy: 0.7793 - val_loss: 1.6254 - val_accuracy: 0.6297\n",
            "Epoch 52/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.6487 - accuracy: 0.7802 - val_loss: 1.6038 - val_accuracy: 0.6350\n",
            "Epoch 53/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6459 - accuracy: 0.7811 - val_loss: 1.5816 - val_accuracy: 0.6422\n",
            "Epoch 54/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6433 - accuracy: 0.7818 - val_loss: 1.5594 - val_accuracy: 0.6485\n",
            "Epoch 55/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.6406 - accuracy: 0.7827 - val_loss: 1.5366 - val_accuracy: 0.6563\n",
            "Epoch 56/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.6381 - accuracy: 0.7836 - val_loss: 1.5138 - val_accuracy: 0.6665\n",
            "Epoch 57/60\n",
            "54000/54000 [==============================] - 1s 14us/sample - loss: 0.6356 - accuracy: 0.7848 - val_loss: 1.4909 - val_accuracy: 0.6727\n",
            "Epoch 58/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.6332 - accuracy: 0.7855 - val_loss: 1.4682 - val_accuracy: 0.6785\n",
            "Epoch 59/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.6309 - accuracy: 0.7866 - val_loss: 1.4450 - val_accuracy: 0.6855\n",
            "Epoch 60/60\n",
            "54000/54000 [==============================] - 1s 15us/sample - loss: 0.6285 - accuracy: 0.7870 - val_loss: 1.4219 - val_accuracy: 0.6910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Fv_2B0j6wW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0d71b4a9-6dd6-4188-cd34-076148b880df"
      },
      "source": [
        "loss,accuracy  = model3.evaluate(testX, testY, verbose=False)\n",
        "print('Accuracy: %.3f'  % accuracy)\n",
        "print('Loss: %.3f' % loss)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.688\n",
            "Loss: 1.428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ64_2--kBIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3oTaTMOlQP_",
        "colab_type": "text"
      },
      "source": [
        "# Review The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc-skX84lLgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "51f3dcb0-1e60-409b-d407-c05152f48386"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_107 (Dense)            multiple                  78500     \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            multiple                  10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc multiple                  400       \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            multiple                  1010      \n",
            "=================================================================\n",
            "Total params: 90,010\n",
            "Trainable params: 89,810\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILb3zW4Vlapn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Conclusion:-\n",
        "# Model 1 performed better with 83.3% accuracy."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}